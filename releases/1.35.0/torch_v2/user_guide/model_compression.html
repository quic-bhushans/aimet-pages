<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AIMET model compression &mdash; AI Model Efficiency Toolkit Documentation: ver 1.35.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/style.css" />
      <link rel="stylesheet" href="../_static/style.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

    
    
    <a href="../torch_docs/index.html" class="icon icon-home">
    AI Model Efficiency Toolkit
      <img src="../_static/brain_logo.png" class="logo" alt="Logo"/>
    </a>
      <div class="version">
        1.35.0
      </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install/install_host.html">Install in Host Machine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/install_docker.html">Install in Docker Container</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/tutorials/quickstart_guide.html">Quickstart Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/examples/ptq.html">Post-Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Feature Descriptions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="adaround.html"> Adaptive Rounding (AdaRound)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AIMET PyTorch API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/quantized_modules.html">Quantized Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/quantizer.html">Quantizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html">QuantizationMixin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html">quantization.affine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/api/quantization/float/index.html">quantization.float</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/encoding_analyzer.html">Encoding Analyzers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../torch_docs/index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../torch_docs/index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">AIMET model compression</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/user_guide/model_compression.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="aimet-model-compression">
<span id="ug-model-compression"></span><h1>AIMET model compression<a class="headerlink" href="#aimet-model-compression" title="Permalink to this heading"></a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading"></a></h2>
<p>AIMET provides a model compression library that can reduce a model’s multiply-and-accumulate (MAC) and memory costs with little loss of accuracy. AIMET supports various compression schemes like weight singular value decomposition (SVD), spatial SVD, and channel pruning.</p>
<div class="toctree-wrapper compound">
</div>
<p>See the <a class="reference internal" href="compression_feature_guidebook.html#ug-comp-guidebook"><span class="std std-ref">Compression Guidebook</span></a> for a summary of how to use the compression features, and how to combine them.</p>
</section>
<section id="use-case">
<h2>Use Case<a class="headerlink" href="#use-case" title="Permalink to this heading"></a></h2>
<p>AIMET can compress a trained model to a specified compression ratio. The model can then be further fine-tuned and exported to a target.</p>
<p>All of the compression schemes in AIMET use a two-phase process:</p>
<ol class="arabic simple">
<li><p>Compression ratio selection</p></li>
<li><p>Model compression</p></li>
</ol>
<img alt="../_images/compression_use_case.PNG" src="../_images/compression_use_case.PNG" />
<p>Both of these phases are explained below.</p>
</section>
<section id="compression-ratio-selection">
<h2>Compression ratio selection<a class="headerlink" href="#compression-ratio-selection" title="Permalink to this heading"></a></h2>
<div class="toctree-wrapper compound">
</div>
<p>In this phase, you select compression ratios automatically and/or manually. You can use AIMET Visualization to inspect these choices.</p>
<dl class="simple">
<dt>Automatic compression ratio selection</dt><dd><p>AIMET computes optimal compression ratios for each layer, using the <a class="reference internal" href="greedy_compression_ratio_selection.html#ug-greedy-comp-ratio-selection"><span class="std std-ref">Greedy Compression Ratio Selection</span></a> method for automatic compression.</p>
</dd>
<dt>Manual compression ratio selection</dt><dd><p>You can manually specify compression ratios by layer. We suggest that you first use automatic compression ratio selection to get a baseline set of compression ratios, then manually change compression ratios for one or more layers.</p>
</dd>
<dt>Visualization</dt><dd><p>Visualize compression as you apply these steps using <a class="reference internal" href="visualization_compression.html"><span class="doc">AIMET Visualization</span></a>.</p>
</dd>
</dl>
</section>
<section id="model-compression">
<h2>Model compression<a class="headerlink" href="#model-compression" title="Permalink to this heading"></a></h2>
<p>In this phase, AIMET applies the compression ratios to each layer to create a compressed model.
AIMET supports the following model compression algorithms:</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="weight_svd.html">Weight SVD</a></li>
<li class="toctree-l1"><a class="reference internal" href="spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l1"><a class="reference internal" href="channel_pruning.html">Channel pruning</a></li>
</ul>
</div>
</section>
<section id="optional-techniques">
<h2>Optional techniques<a class="headerlink" href="#optional-techniques" title="Permalink to this heading"></a></h2>
<p>AIMET supports the following optional techniques that can improve compression results.</p>
<ul class="simple">
<li><p>Rank-rounding</p></li>
<li><p>Per-layer fine-tuning</p></li>
</ul>
<section id="rank-rounding">
<h3>Rank Rounding<a class="headerlink" href="#rank-rounding" title="Permalink to this heading"></a></h3>
<p>AIMET techniques like weight SVD, spatial SVD, and channel pruning decompose or reduce input and output channel layers.</p>
<p>Certain types of layers (such as 2D convolution (Conv2D) or fully connected (FC)) in embedded ML accelerators are often optimized for certain multiplicities. Matching the expected multiplicity gives optimal runtime performance for that layer.</p>
<p>The rank-rounding feature in AIMET tries to reduce layers to match a user-provided multiplicity. AIMET only allows you to specify a multiplicity factor for the entire model, not per layer. Use this feature to optimize models to run on embedded targets. By default the feature is disabled.</p>
</section>
<section id="per-layer-fine-tuning">
<h3>Per-layer fine-tuning<a class="headerlink" href="#per-layer-fine-tuning" title="Permalink to this heading"></a></h3>
<p>For a given user model and compression ratio, compression sometimes causes a sharp drop in accuracy before fine-tuning. Per-layer fine-tuning is a technique that can help maintain model accuracy for desired compression ratios.</p>
<p>In this feature, AIMET invokes a user-provided fine-tuning function after compressing every layer that was selected for compression. This fine tuning is done during the model compression phase described above.</p>
<div class="admonition-note admonition">
<p class="admonition-title">NOTE</p>
<p>This feature may require careful selection of learning rates and learning-rate-decay parameters to be used during fine-tuning. You are responsible for choosing these training parameters.</p>
</div>
</section>
</section>
<section id="faqs">
<h2>FAQs<a class="headerlink" href="#faqs" title="Permalink to this heading"></a></h2>
<ol class="arabic">
<li><p>Which is the best technique to use for compression?</p>
<p><em>We see best results when Spatial SVD is performed followed by Channel Pruning.</em></p>
</li>
<li><p>Can I combine the different techniques?</p>
<p><em>Yes, different techniques can be combined to get better accuracy. Compression can be also combined with post-training quantization techniques to get a better model for target.</em></p>
</li>
<li><p>How do I take a model to target after compression?</p>
<p><em>First, compress the model using the techniques described above. Then, quantize the model and export it to target.</em></p>
</li>
<li><p>Greedy rank selection is very slow. Can something be done to speed it up?</p>
<p><em>The time-consuming part is creating the eval-score dictionary, not greedy rank selection itself. A single eval-score dictionary can be generated once and then loaded into the searcher for different experiments. Or, reduce the number of candidates over which the eval-score dictionary is created, but be aware that the fewer candidates, the worse the granularity. The default value of 10 candidates usually strikes a good balance.</em></p>
</li>
<li><p>Is per-layer fine tuning helpful?</p>
<p><em>Per-layer fine tuning is an experimental technique. We have not observed major gains by using it. But, you can try it to see if it works for your model. In practice, the best results seem to come from doing one epoch of fine-tuning per layer, and then doing 10-15 epochs of fine-tuning for the entire compressed model at the end.</em></p>
</li>
</ol>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Xiangyu Zhang, Jianhua Zou, Kaiming He, and Jian Sun. “Accelerating Very Deep Convolutional Networks for Classification and Detection.” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 38, no. 10, pp. 1943-1955, 1 Oct. 2016.</p></li>
<li><p>Yihui He, Xiangyu Zhang, and Jian Sun. “Channel Pruning for Accelerating Very Deep Neural Networks.” IEEE International Conference on Computer Vision (ICCV), Venice, 2017, pp. 1398-1406.</p></li>
<li><p>Max Jaderberg, Andrea Vedaldi, and Andrew Zisserman. “Speeding up Convolutional Neural Networks with Low Rank Expansions.” British Machine Vision Conference, Jan. 2014.</p></li>
<li><p>Andrey Kuzmin, Markus Nagel, Saurabh Pitre, Sandeep Pendyam, Tijmen Blankevoort, Max Welling. “Taxonomy and Evaluation of Structured Compression of Convolutional Neural Networks.”</p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>