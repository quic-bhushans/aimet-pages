<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AIMET quantization simulation &mdash; AI Model Efficiency Toolkit Documentation: ver 1.35.0</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/style.css" />
      <link rel="stylesheet" href="../_static/style.css" type="text/css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

    
    
    <a href="../torch_docs/index.html" class="icon icon-home">
    AI Model Efficiency Toolkit
      <img src="../_static/brain_logo.png" class="logo" alt="Logo"/>
    </a>
      <div class="version">
        1.35.0
      </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install/install_host.html">Install in Host Machine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/install_docker.html">Install in Docker Container</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/tutorials/quickstart_guide.html">Quickstart Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/examples/ptq.html">Post-Training Quantization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Feature Descriptions</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="adaround.html"> Adaptive Rounding (AdaRound)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">AIMET PyTorch API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/quantized_modules.html">Quantized Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/quantizer.html">Quantizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/api/nn.quantization_mixin.html">QuantizationMixin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/api/quantization/affine/index.html">quantization.affine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/api/quantization/float/index.html">quantization.float</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_docs/encoding_analyzer.html">Encoding Analyzers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../torch_docs/index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../torch_docs/index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">AIMET quantization simulation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/user_guide/quantization_sim.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="aimet-quantization-simulation">
<span id="ug-quantsim"></span><h1>AIMET quantization simulation<a class="headerlink" href="#aimet-quantization-simulation" title="Permalink to this heading"></a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading"></a></h2>
<p>AIMET’s Quantization Simulation feature simulates the effects of quantized hardware. This enables you to apply post-training and/or fine-tuning techniques in AIMET to recover the accuracy lost in quantization before deploying the model to the target device.</p>
<p>When QuantSim is applied by itself, AIMET finds optimal quantization scale/offset parameters for each quantizer but does not apply techniques to mitigate accuracy loss. You can apply QuantSim directly to the original model or to a model updated using Post-Training Quantization.</p>
<p>Once a QuantSim object has been created, you can fine-tune the model using its existing pipeline. This technique is described in <a class="reference internal" href="quantization_aware_training.html#ug-quantization-aware-training"><span class="std std-ref">Quantization Aware Training</span></a>.</p>
<p>The quantization nodes used in QuantSim are custom quantizers defined in AIMET, and are not recognized by targets.
QuantSim provides an export functionality that saves a copy of the model with quantization nodes removed and generates an encodings file containing quantization scale and offset parameters for activation and weight tensors in the model.</p>
<p>A hardware runtime can ingest the encodings file and match it with the exported model to apply scale and offset values in the model.</p>
</section>
<section id="quantsim-workflow">
<h2>QuantSim workflow<a class="headerlink" href="#quantsim-workflow" title="Permalink to this heading"></a></h2>
<p>Following is a typical workflow for using AIMET QuantSim to simulate on-target quantized accuracy.</p>
<ol class="arabic simple">
<li><p>Start with a pretrained floating-point (FP32) model.</p></li>
<li><p>Use AIMET to create a simulation model. AIMET inserts quantization simulation operations into the model graph (explained in the sub-section below).</p></li>
<li><p>AIMET configures the inserted simulation operations. The configuration of these operations can be controlled via a configuration file as discussed below.</p></li>
<li><p>Provide a callback method that feeds representative data samples through the model. AIMET uses this method to find optimal quantization parameters, such as scales and offsets, for the inserted quantization simulation operations. These samples can be from the training or calibration datasets. 1,000-2,000 samples are usually sufficient to optimize quantization parameters.</p></li>
<li><p>AIMET returns a quantization simulation model that can be used as a drop-in replacement for the original model in
your evaluation pipeline. Running this simulation model through the evaluation pipeline yields a quantized accuracy
metric that closely simulates on-target accuracy.</p></li>
<li><p>Call <cite>.export()</cite> on the sim object to save a copy of the model with quantization nodes removed, along with
an encodings file containing quantization scale and offset parameters for each activation and weight tensor in the model.</p></li>
</ol>
</section>
<section id="simulating-quantization-noise">
<h2>Simulating quantization noise<a class="headerlink" href="#simulating-quantization-noise" title="Permalink to this heading"></a></h2>
<p>The diagram below illustrates how quantization noise is introduced to a model when its inputs, outputs, or parameters are quantized and de-quantized.</p>
<blockquote>
<div><img alt="../_images/quant_3.png" src="../_images/quant_3.png" />
</div></blockquote>
<p>A de-quantizated value is not exactly equal to its corresponding quantized value. The difference between the two values is the quantization noise.</p>
<p>To simulate quantization noise, AIMET QuantSim adds quantizer operations to the PyTorch, TensorFlow, or Keras model graph. The resulting model graph can be used as-is in your evaluation or training pipeline.</p>
</section>
<section id="determining-quantization-parameters-encodings">
<h2>Determining quantization parameters (encodings)<a class="headerlink" href="#determining-quantization-parameters-encodings" title="Permalink to this heading"></a></h2>
<p>Using a QuantSim model, AIMET determines the optimal quantization encodings (scale and offset parameters) for each quantizer operation.</p>
<p>To do this, AIMET passes calibration samples through the model and, using hooks, intercepts tensor data flowing through the model. AIMET creates a histogram to model the distribution of the floating point values in the output tensor for each layer.</p>
<img alt="../_images/quant_2.png" src="../_images/quant_2.png" />
<p>An encoding for a layer consists of four numbers:</p>
<dl class="simple">
<dt>Min (q<sub>min</sub>)</dt><dd><p>Numbers below these are clamped</p>
</dd>
<dt>Max (q<sub>max</sub>)</dt><dd><p>Numbers above these are clamped</p>
</dd>
<dt>Delta</dt><dd><p>Granularity of the fixed point numbers (a function of the selected bit-width)</p>
</dd>
<dt>Offset</dt><dd><p>Offset from zero</p>
</dd>
<dt>The Delta and Offset are calculated using Min and Max and vice versa using the equations:</dt><dd><p><span class="math notranslate nohighlight">\(\textrm{Delta} = \dfrac{\textrm{Max} - \textrm{Min}}{{2}^{\textrm{bitwidth}} - 1} \quad \textrm{Offset} = \dfrac{-\textrm{Min}}{\textrm{Delta}}\)</span></p>
</dd>
</dl>
<p>Using the floating point distribution in the output tensor for each layer, AIMET calculates quantization encodings using the specified quantization calibration technique described in the next section.</p>
</section>
<section id="quantization-schemes">
<h2>Quantization schemes<a class="headerlink" href="#quantization-schemes" title="Permalink to this heading"></a></h2>
<p>AIMET supports various techniques, also called quantization schemes, for calculating min and max values for encodings:</p>
<p><strong>Min-Max (also referred to as “TF” in AIMET)</strong></p>
<blockquote>
<div><p>(The name “TF” derives from the origin of the technique and has no relation to which framework is using it.)</p>
<p>To cover the whole dynamic range of the tensor, the quantization parameters Min and Max are defined as the observed Min and Max during the calibration process. This approach eliminates clipping error but is sensitive to outliers since extreme values induce rounding errors.</p>
</div></blockquote>
<p><strong>Signal-to-Quantization-Noise (SQNR; also called “TF Enhanced” in AIMET)</strong></p>
<blockquote>
<div><p>(The name “TF Enhanced” derives from the origin of the technique and has no relation to which framework is using it.)</p>
<p>The SQNR approach is similar to the mean square error (MSE) minimization approach. The qmin and qmax are found that minimize the total MSE between the original and the quantized tensor.</p>
<p>Quantization noise and saturation noise are different types of erros which are weighted differently.</p>
</div></blockquote>
<p>For each quantization scheme, there are “post training” and “training range learning” variants. The “post training” variants are used during regular QuantSim inference and QAT without Range Learning to compute initial encoding values for each quantization node. In QAT without Range Learning, encoding values for activation quantizers remain static (encoding values for parameter quantizers change with changing parameter values during training).</p>
<p>The “training range learning” variants are used during QAT with Range Learning. The schemes define how to compute initial encoding values for each quantization node, but also allow encoding values for activations to be learned alongside parameter quantizer encodings during training.</p>
<p>For more details on QAT, see <a class="reference internal" href="quantization_aware_training.html#ug-quantization-aware-training"><span class="std std-ref">Quantization Aware Training</span></a>.</p>
</section>
<section id="configuring-quantization-simulation-operations">
<h2>Configuring quantization simulation operations<a class="headerlink" href="#configuring-quantization-simulation-operations" title="Permalink to this heading"></a></h2>
<p>Different hardware and on-device runtimes support different quantization choices for neural network inference. For example, some runtimes support asymmetric quantization for both activations and weights, whereas others support asymmetric quantization just for weights.</p>
<p>As a result, quantization choices during simulation need to best reflect the target runtime and hardware. AIMET provides a default configuration file that can be modified. By default, the following configuration is used for quantization simulation:</p>
<dl class="simple">
<dt>Weight quantization</dt><dd><p>Per-channel, symmetric quantization, INT8</p>
</dd>
<dt>Activation or layer output quantization</dt><dd><p>Per-tensor, asymmetric quantization, INT8</p>
</dd>
</dl>
<p>Quantization options settable in the configuration file include:</p>
<ul class="simple">
<li><p>Enabling or disabling input and output quantizer ops</p></li>
<li><p>Enabling or disabling parameter quantizer ops</p></li>
<li><p>Enabling or disabling model input quantizer</p></li>
<li><p>Enabling or disabling model output quantizer</p></li>
<li><p>Symmetric or asymmetric quantization</p></li>
<li><p>Unsigned or signed symmetric quantization</p></li>
<li><p>Strict or non-strict symmetric quantization</p></li>
<li><p>Per-channel or per-tensor quantization</p></li>
<li><p>Defining groups of layers to be fused (no quantization is done on intermediate tensors within fused layers)</p></li>
</ul>
<p>See the <a class="reference internal" href="quantization_configuration.html#ug-quantsim-config"><span class="std std-ref">Quantization Simulation Configuration</span></a> page, which describes the configuration options in detail.</p>
</section>
<section id="quantization-simulation-apis">
<h2>Quantization Simulation APIs<a class="headerlink" href="#quantization-simulation-apis" title="Permalink to this heading"></a></h2>
<p>See the AIMET Quantization Simulation API for your platform:</p>
<ul class="simple">
<li><p><span class="xref std std-ref">Quantization Simulation for PyTorch</span></p></li>
<li><p><span class="xref std std-ref">Quantization Simulation for Keras</span></p></li>
<li><p><span class="xref std std-ref">Quantization Simulation for ONNX</span></p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>