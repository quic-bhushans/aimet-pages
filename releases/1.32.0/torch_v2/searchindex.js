Search.setIndex({"docnames": ["install/index", "install/install_docker", "install/install_host", "toplevelhidden", "torch_docs/api/nn.fake_quantization_mixin", "torch_docs/api/nn.quantization_mixin", "torch_docs/api/q.quantized_tensor", "torch_docs/encoding_analyzer", "torch_docs/examples/ptq", "torch_docs/index", "torch_docs/quantized_modules", "torch_docs/quantizer", "torch_docs/tutorials/quickstart", "user_guide/adaround", "user_guide/auto_quant", "user_guide/bn_reestimation", "user_guide/channel_pruning", "user_guide/compression_feature_guidebook", "user_guide/greedy_compression_ratio_selection", "user_guide/index", "user_guide/known_issues", "user_guide/model_compression", "user_guide/model_guidelines", "user_guide/model_quantization", "user_guide/post_training_quant_techniques", "user_guide/quant_analyzer", "user_guide/quantization_aware_training", "user_guide/quantization_configuration", "user_guide/quantization_feature_guidebook", "user_guide/quantization_sim", "user_guide/release_notes", "user_guide/spatial_svd", "user_guide/visualization_compression", "user_guide/visualization_quant", "user_guide/weight_svd", "user_guide/winnowing"], "filenames": ["install/index.rst", "install/install_docker.rst", "install/install_host.rst", "toplevelhidden.rst", "torch_docs/api/nn.fake_quantization_mixin.rst", "torch_docs/api/nn.quantization_mixin.rst", "torch_docs/api/q.quantized_tensor.rst", "torch_docs/encoding_analyzer.rst", "torch_docs/examples/ptq.rst", "torch_docs/index.rst", "torch_docs/quantized_modules.rst", "torch_docs/quantizer.rst", "torch_docs/tutorials/quickstart.rst", "user_guide/adaround.rst", "user_guide/auto_quant.rst", "user_guide/bn_reestimation.rst", "user_guide/channel_pruning.rst", "user_guide/compression_feature_guidebook.rst", "user_guide/greedy_compression_ratio_selection.rst", "user_guide/index.rst", "user_guide/known_issues.rst", "user_guide/model_compression.rst", "user_guide/model_guidelines.rst", "user_guide/model_quantization.rst", "user_guide/post_training_quant_techniques.rst", "user_guide/quant_analyzer.rst", "user_guide/quantization_aware_training.rst", "user_guide/quantization_configuration.rst", "user_guide/quantization_feature_guidebook.rst", "user_guide/quantization_sim.rst", "user_guide/release_notes.rst", "user_guide/spatial_svd.rst", "user_guide/visualization_compression.rst", "user_guide/visualization_quant.rst", "user_guide/weight_svd.rst", "user_guide/winnowing.rst"], "titles": ["AIMET Installation", "AIMET Installation in Docker", "AIMET Installation and Setup", "&lt;no title&gt;", "nn.FakeQuantizationMixin", "nn.QuantizationMixin", "quantization.QuantizedTensor", "Encoding Analyzers", "Post-Training Quantization", "Welcome to AI Model Efficiency Toolkit PyTorch API Docs!", "Quantized Modules", "Quantizers", "Quickstart Guide", "AIMET AdaRound", "AIMET AutoQuant", "AIMET BN Re-estimation", "AIMET Channel Pruning", "AIMET Compression Features Guidebook", "AIMET Greedy Compression Ratio Selection", "AI Model Efficiency Toolkit User Guide", "AIMET Known Issues", "AIMET Model Compression", "Model Guidelines for PyTorch", "AIMET Model Quantization", "AIMET Post-Training Quantization Techniques", "AIMET QuantAnalyzer", "AIMET Quantization Aware Training", "Quantization Simulation Configuration", "AIMET Quantization Features Guidebook", "AIMET Quantization Simulation", "AIMET Release Notes", "AIMET Spatial SVD", "AIMET Visualization", "AIMET Visualization for Quantization", "AIMET Weight SVD", "AIMET Winnowing"], "terms": {"ar": [0, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 35], "host": [0, 1, 30, 32], "http": [0, 1, 2, 17, 24, 30, 32], "github": [0, 1, 2, 17, 30], "com": [0, 1, 2, 30], "quic": [0, 1, 2, 17, 30], "each": [0, 1, 4, 5, 10, 11, 16, 17, 18, 23, 24, 25, 26, 27, 28, 29, 33, 35], "includ": [0, 5, 15, 21, 23, 25, 27, 29, 30], "multipl": [0, 2, 6, 10, 19, 21, 23, 30], "python": [0, 1, 2], "follow": [0, 1, 2, 9, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 29, 31, 34, 35], "format": [0, 11, 14, 20], "package_prefix": 0, "variant": [0, 2, 26, 29], "_": [0, 1, 2, 10], "version": [0, 1, 2, 5, 9, 10, 19], "cp310": [0, 1, 2], "linux_x86_64": [0, 1, 2], "whl": [0, 1, 2], "pleas": [0, 1, 2, 9, 13, 16, 19, 21, 25, 29], "find": [0, 18, 23, 25, 26, 29], "more": [0, 10, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 32, 33], "inform": [0, 23, 25], "below": [0, 1, 2, 10, 14, 15, 23, 24, 27, 28, 29, 35], "about": 0, "pytorch": [0, 1, 4, 5, 10, 15, 19, 25, 27, 29, 30], "torch": [0, 1, 4, 5, 6, 10, 22, 30], "gpu": [0, 1, 23, 30], "1": [0, 1, 4, 5, 10, 18, 20, 21, 22, 23, 27, 28, 29, 31, 34, 35], "13": [0, 1], "3": [0, 7, 17, 23, 26, 28, 35], "10": [0, 1, 2, 4, 5, 10, 18, 21, 26], "cuda": [0, 2], "11": [0, 2], "x": [0, 10, 17, 22, 25], "recommend": [0, 13, 15, 17, 23, 28], "us": [0, 2, 5, 7, 9, 15, 16, 17, 18, 19, 22, 24, 25, 26, 27, 28, 29, 30, 33], "model": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "cpu": [0, 1, 2, 23, 30], "If": [0, 1, 2, 5, 7, 10, 14, 22, 23, 24, 25, 27, 28, 32, 33, 35], "machin": [0, 1, 21], "without": [0, 4, 5, 10, 14, 23, 26, 29, 35], "pt21": [0, 1], "2": [0, 1, 13, 23, 28, 29], "tensorflow": [0, 1, 9, 15, 19, 20, 27, 29, 30], "tf": [0, 1, 25, 29, 30], "onnx": [0, 1, 9, 19, 22, 23, 27], "14": 0, "The": [0, 2, 6, 7, 9, 10, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35], "platform": [0, 23], "setup": 0, "64": [0, 7, 13], "bit": [0, 13, 15, 23, 28, 29, 30], "intel": 0, "x86": 0, "compat": 0, "processor": 0, "linux": [0, 2], "ubuntu": [0, 2], "22": [0, 2], "04": [0, 2], "lt": [0, 2], "bash": [0, 1], "command": [0, 1, 2, 32], "shell": 0, "For": [0, 1, 2, 13, 16, 17, 18, 19, 20, 21, 23, 25, 27, 29, 32, 35], "nvidia": [0, 1, 2], "card": 0, "comput": [0, 2, 4, 5, 7, 13, 21, 22, 23, 24, 25, 29, 32, 35], "capabl": [0, 10, 32, 33], "5": [0, 10, 17, 26, 28], "later": 0, "docker": 0, "To": [0, 9, 10, 15, 18, 21, 22, 25, 27, 28, 29, 32, 33], "acceler": [0, 9, 19, 21], "train": [0, 9, 13, 14, 15, 19, 21, 28, 29, 30], "modul": [0, 4, 5, 9, 13, 23, 30, 35], "an": [0, 6, 9, 10, 11, 13, 14, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 33, 35], "enabl": [0, 1, 9, 15, 19, 23, 25, 27, 29, 30], "minimum": 0, "driver": [0, 2], "455": 0, "i": [0, 1, 2, 4, 5, 7, 9, 10, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35], "latest": [0, 1], "alwai": [0, 18], "especi": [0, 23, 26, 28], "newer": 0, "both": [0, 5, 10, 23, 24, 26, 27, 28, 29, 31, 35], "cudnn": 0, "advanc": 0, "interfac": 0, "support": [0, 16, 17, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 34, 35], "hardwar": [0, 23, 24, 29], "i7": 0, "multicor": 0, "w": [0, 1, 35], "hyperthread": 0, "16": [0, 4, 5, 10, 13], "gb": 0, "ram": 0, "500gb": 0, "ssd": 0, "hard": 0, "drive": 0, "geforc": 0, "gtx": 0, "1080": 0, "tesla": 0, "v100": 0, "while": [0, 10, 13, 18, 22, 23, 26, 28, 29, 32], "thei": [0, 27, 32], "good": [0, 13], "perform": [0, 10, 14, 15, 16, 17, 18, 21, 23, 24, 25, 26, 28], "when": [0, 7, 9, 10, 13, 19, 21, 23, 24, 25, 26, 27, 28, 29, 32, 33, 35], "larg": [0, 17, 26, 31, 34], "network": [0, 10, 14, 17, 18, 21, 23, 26, 28, 29, 32, 34], "There": [0, 13, 22, 24, 26, 32, 33], "two": [0, 10, 18, 19, 21, 23, 24, 25, 26, 29, 31, 32, 33, 34], "wai": [0, 18], "On": 0, "your": [0, 1, 2, 22], "our": [0, 2, 9, 18, 28, 29], "pre": [0, 1, 2, 9, 19, 24], "built": [0, 1], "develop": [0, 1, 2, 4, 5, 10], "imag": [0, 13, 25], "click": 0, "appropri": [0, 1, 2, 10, 17, 18, 21, 28], "link": [0, 9], "contain": [0, 10, 23, 25, 26, 27, 29], "qualcomm": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "innov": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "center": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "inc": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "ai": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "effici": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "toolkit": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "aimet_common": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "quantsim_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "default_config": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "json": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], "thi": [1, 2, 4, 5, 6, 9, 10, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35], "page": [1, 2, 9, 17, 29, 30], "provid": [1, 2, 9, 10, 13, 17, 18, 21, 23, 24, 25, 27, 28, 29, 32, 33, 35], "instruct": [1, 2, 9], "insid": [1, 4, 5, 10], "variant_str": [1, 2], "ONE": [1, 2], "depend": [1, 2, 17, 18, 23, 27, 30], "desir": [1, 2, 17, 21, 23, 28], "export": [1, 2, 9, 15, 19, 21, 22, 23, 26, 29, 30], "aimet_vari": [1, 2], "one": [1, 10, 16, 21, 26, 27, 30, 31, 34], "workspac": 1, "absolute_path_to_workspac": 1, "docker_image_nam": 1, "artifact": 1, "codelinaro": 1, "org": [1, 2, 24], "dev": [1, 2], "docker_container_nam": 1, "any_nam": 1, "note": [1, 2, 6, 16, 17, 18, 19, 21, 22, 23, 25], "feel": 1, "free": [1, 23, 24, 26], "modifi": [1, 2, 23, 29, 30, 35], "need": [1, 14, 17, 21, 23, 24, 25, 26, 27, 29, 30, 32, 33], "onli": [1, 2, 6, 10, 15, 20, 23, 25, 26, 27, 30, 35], "you": [1, 2, 18, 22, 31, 34], "want": [1, 2], "skip": [1, 16], "next": [1, 28], "section": [1, 2, 13, 15, 16, 21, 23, 29], "any_tag": 1, "t": [1, 13], "f": [1, 2], "jenkin": 1, "dockerfil": 1, "ensur": [1, 10, 23, 28], "name": [1, 10, 11, 24, 29, 30, 32], "alreadi": [1, 18, 28], "run": [1, 10, 15, 19, 21, 23, 24, 25, 29, 30, 32], "otherwis": [1, 2, 28], "remov": [1, 16, 19, 29, 35], "exist": [1, 23, 29], "new": [1, 23, 27, 30], "p": 1, "grep": 1, "kill": 1, "rm": 1, "u": [1, 28], "id": [1, 32], "user": [1, 9, 10, 13, 14, 17, 21, 23, 25, 26, 27, 28, 29, 30, 32, 33], "g": [1, 9, 15, 17, 19, 28, 35], "v": [1, 18], "etc": [1, 2, 17, 23], "passwd": 1, "ro": 1, "group": [1, 27, 29], "home": 1, "mnt": 1, "entrypoint": 1, "bin": [1, 2, 7], "hostnam": 1, "abov": [1, 2, 9, 14, 15, 18, 19, 21, 22, 24, 28, 29, 35], "base": [1, 4, 5, 7, 10, 11, 16, 17, 23], "filesystem": 1, "0": [1, 2, 4, 5, 7, 10, 13, 17, 18, 22, 27], "add": [1, 10, 27, 29, 30, 32, 33, 35], "all": [1, 4, 5, 10, 16, 18, 21, 24, 25, 27, 28], "order": [1, 2, 15, 16, 17, 23, 26, 29, 33], "access": [1, 23], "replac": [1, 10, 24, 29], "port": [1, 32], "forward": [1, 5, 10, 11, 22, 25, 28, 30], "done": [1, 16, 21, 27, 29, 35], "visual": [1, 21, 23, 24, 25, 28, 30, 31, 34], "api": [1, 13, 14, 19, 22, 23, 25, 27, 30, 32], "can": [1, 9, 10, 14, 15, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34], "achiev": [1, 13, 17, 18, 31, 34], "port_id": 1, "ani": [1, 2, 5, 9, 13, 14, 27, 30], "number": [1, 7, 9, 13, 18, 19, 21, 26, 29, 30, 32, 35], "through": [1, 10, 24, 25, 29, 32, 33], "method": [1, 6, 10, 18, 21, 23, 28, 29], "go": [1, 2, 32], "project": 1, "identifi": [1, 2, 25, 28, 30, 35], "wish": 1, "should": [1, 6, 17, 21, 27, 32, 35], "31": 1, "32": [1, 28], "sudo": [1, 2], "apt": [1, 2], "get": [1, 2, 13, 16, 23, 33], "liblapack": 1, "y": [1, 2, 25], "pip": [1, 2], "altern": [1, 2, 21], "we": [1, 10, 18, 21, 23, 24, 27, 28, 29, 33], "tag": [1, 2, 30], "file": [1, 2, 23, 25, 26, 29, 30, 33], "torch_gpu": [1, 2], "torch_cpu": [1, 2], "tf_gpu": [1, 2], "tf_cpu": [1, 2], "onnx_gpu": [1, 2], "onnx_cpu": [1, 2], "release_tag": [1, 2], "step": [1, 13, 14, 15, 16, 17, 18, 21, 23, 24, 26, 28, 29], "download": [1, 2], "url": [1, 2, 32], "download_url": [1, 2], "common": [1, 28, 33], "suffix": [1, 2], "wheel_file_suffix": [1, 2], "specifi": [1, 2, 14, 21, 27, 29, 33], "pend": [1, 2], "pip3": [1, 2], "h": [1, 2, 34, 35], "These": [1, 2, 10, 14, 15, 16, 17, 22, 23, 24, 25, 28, 29], "assum": [1, 2], "path": [1, 2], "usr": [1, 2], "lib": [1, 2], "python3": [1, 2], "dist": [1, 2], "case": [1, 2, 10, 18, 24, 26, 27], "accordingli": [1, 2], "automat": [1, 2, 17, 21, 23, 25, 30], "m": [1, 2], "aimet_torch": [1, 2, 4, 5, 6, 7, 10, 11, 22], "torch_stabl": [1, 2], "html": [1, 2, 17, 25, 30, 33], "OR": [1, 2], "aimet_tensorflow": [1, 2], "aimet_onnx": [1, 2], "variabl": [1, 2], "sourc": [1, 2, 4, 5, 6, 7, 10, 11, 28], "envsetup": [1, 2], "sh": [1, 2], "unless": [2, 35], "local": [2, 32], "basic": 2, "requisit": 2, "updat": [2, 11, 23, 24, 26, 29, 30], "upgrad": 2, "ye": [2, 21], "wget": 2, "gnupg2": 2, "have": [2, 5, 18, 21, 23, 24, 25, 28, 29], "set": [2, 5, 7, 10, 11, 13, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 35], "default": [2, 5, 10, 13, 18, 21, 27, 29, 30, 32], "do": [2, 21, 25, 29], "releas": [2, 22], "were": [2, 17, 23, 27, 35], "test": 2, "7": [2, 35], "8": [2, 4, 5, 10, 23, 35], "sub": [2, 16, 21, 29, 35], "correspond": [2, 10, 16, 18, 23, 25, 35], "visit": [2, 9, 19], "archiv": 2, "obtain": [2, 16, 17, 25, 29], "correct": [2, 13, 15, 23, 24, 28], "exact": [2, 10, 15], "up": [2, 21, 26, 27, 29, 35], "date": 2, "repo": 2, "ubuntu2204": 2, "x86_64": 2, "pin": 2, "mv": 2, "prefer": [2, 21], "d": 2, "repositori": 2, "600": 2, "local_instal": 2, "local_11": 2, "515": 2, "65": [2, 17], "01": [2, 13], "1_amd64": 2, "deb": 2, "kei": 2, "adv": 2, "fetch": 2, "3bf863cc": 2, "pub": 2, "dpkg": 2, "cp": [2, 17], "var": 2, "keyr": 2, "gpg": 2, "share": [2, 10], "echo": 2, "list": [2, 7, 10, 11, 18, 20, 22, 27], "520": 2, "61": 2, "05": 2, "torch_gpu_pt21": 2, "torch_cpu_pt21": 2, "cp38": 2, "cp36": 2, "cp36m": 2, "cp37": 2, "cp37m": 2, "py3": 2, "none": [2, 5, 10, 11, 32], "actual": [2, 17, 23], "wheel": 2, "filenam": 2, "": [2, 5, 9, 10, 11, 17, 20, 21, 23, 24, 25, 26, 28, 29, 32, 33, 35], "manylinux_2_34_x86_64": 2, "cat": 2, "reqs_deb_common": 2, "txt": 2, "xarg": 2, "reqs_deb_torch_common": 2, "reqs_deb_onnx_common": 2, "reqs_deb_tf_gpu": 2, "reqs_deb_torch_gpu": 2, "reqs_deb_onnx_gpu": 2, "option": [2, 5, 7, 11, 13, 25, 27, 29, 32], "uninstal": 2, "cach": 2, "dir": 2, "9": [2, 28], "post1": 2, "onnxruntime_v": 2, "c": [2, 17], "import": [2, 10, 15, 16, 28], "print": [2, 4, 5, 10, 23, 25], "__version__": 2, "ln": 2, "gnu": 2, "libjpeg": 2, "so": [2, 10, 22, 25, 32], "chose": 2, "between": [2, 10, 24, 25, 27, 29], "featur": [4, 5, 10, 13, 14, 15, 21, 24, 25, 29, 30, 32, 33], "under": [4, 5, 10, 25, 27, 32, 33], "heavi": [4, 5, 10, 32, 33], "chang": [4, 5, 10, 13, 21, 25, 26, 27, 29, 33, 35], "mai": [4, 5, 10, 13, 17, 21, 23, 24, 25, 27, 28, 29], "occur": [4, 5, 10], "notic": [4, 5, 10, 21], "futur": [4, 5, 10], "verion": [4, 5, 10], "mixin": [4, 5, 10], "ad": [4, 5, 20, 23, 27, 30], "fake": [4, 10], "quantiz": [4, 5, 7, 9, 13, 14, 15, 17, 19, 21, 25, 30, 32], "function": [4, 5, 6, 10, 13, 18, 21, 22, 23, 25, 29, 30, 32, 33], "subclass": [4, 5], "class": [4, 5, 6, 7, 10, 11], "v2": [4, 5, 6, 7, 10, 11], "arg": [4, 5, 6, 10], "kwarg": [4, 5, 6, 10], "implement": [4, 5, 10, 22, 28], "regular": [4, 5, 10, 13, 23, 29], "compute_encod": [4, 5, 10, 11], "enter": [4, 5, 10, 14], "context": [4, 5, 10], "quantizerbas": [4, 5, 10, 11], "object": [4, 5, 7, 10, 11, 15, 23, 26, 29], "layer": [4, 5, 10, 13, 14, 15, 16, 17, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35], "observ": [4, 5, 7, 10, 11, 18, 21, 23, 24, 25, 26, 29], "input": [4, 5, 10, 11, 16, 21, 25, 27, 29, 31, 32, 34, 35], "pass": [4, 5, 9, 10, 19, 22, 23, 24, 25, 26, 28, 29, 30, 32], "encod": [4, 5, 6, 9, 11, 13, 15, 23, 25, 26, 30], "upon": [4, 5, 10], "exit": [4, 5, 10], "exampl": [4, 5, 10, 13, 17, 18, 19, 23, 25, 27, 29, 30, 35], "qlinear": [4, 5, 10], "quantizedlinear": [4, 5, 10], "output_quant": [4, 5, 10], "symmetr": [4, 5, 7, 10, 11, 27, 29], "fals": [4, 5, 10, 22, 27], "randn": [4, 5, 10], "is_initi": [4, 5, 10, 11], "true": [4, 5, 7, 10, 11, 22, 27], "classmethod": [4, 5, 10], "module_cl": [4, 5], "decor": [4, 5], "regist": [4, 5, 10, 11], "given": [4, 5, 14, 16, 18, 19, 21, 24, 31, 32, 34], "wrap": [4, 5], "return": [4, 5, 6, 7, 9, 10, 11, 14, 18, 19, 25, 29], "type": [4, 5, 6, 7, 10, 11, 23, 25, 27, 29, 32], "full": [5, 34], "abil": [5, 30], "output": [5, 10, 11, 16, 21, 24, 25, 27, 29, 30, 31, 34, 35], "paramet": [5, 7, 10, 11, 13, 15, 16, 21, 22, 23, 24, 25, 26, 27, 33], "well": [5, 10, 17, 21, 23, 24, 25, 29, 31], "oper": [5, 10, 22, 23, 24, 27, 28], "allow": [5, 10, 14, 19, 21, 23, 25, 26, 27, 28, 29, 30, 32], "dispatch": 5, "librari": [5, 21], "place": [5, 26, 27], "nativ": [5, 10], "get_default_kernel": 5, "kernel": [5, 10, 16, 31, 34], "callabl": 5, "get_kernel": 5, "instanc": [5, 10, 32], "current": [5, 16, 19, 20, 21, 22, 27, 31, 34], "doe": [5, 10, 18, 20, 23, 28], "try": [5, 14, 16, 18, 21, 23, 28], "set_default_kernel": 5, "set_kernel": 5, "underli": [5, 28], "tensor": [6, 7, 10, 11, 13, 16, 22, 23, 25, 27, 28, 29, 30, 31, 34], "repres": [6, 10, 11, 18, 23, 24, 25, 26, 29], "dequant": [6, 10, 11, 29], "associ": [6, 11, 23], "dequantizedtensor": [6, 11], "must": [6, 9, 10, 15, 19, 20, 25, 27, 35], "idempot": 6, "result": [6, 7, 10, 13, 14, 16, 17, 19, 24, 25, 26, 27, 29], "call": [6, 10, 15, 21, 23, 25, 27, 29, 30, 31, 34], "time": [6, 14, 21, 22, 26, 32], "equal": [6, 7, 13, 14, 17, 18, 22, 23, 24, 25, 33], "onc": [6, 15, 16, 21, 25, 26, 29], "In": [6, 10, 13, 14, 17, 18, 21, 23, 24, 26, 27, 29, 33, 35], "other": [6, 18, 20, 21, 23, 25, 28, 29, 30], "word": 6, "duplic": 6, "quantized_repr": 6, "represent": 6, "data": [6, 13, 15, 20, 23, 24, 25, 26, 28, 29], "self": [6, 7], "dtype": 6, "statist": [7, 10, 11, 15, 23, 25, 33], "encoding_analyz": [7, 11], "encodinganalyz": 7, "minmaxencodinganalyz": 7, "shape": [7, 10, 11, 25], "min": [7, 25, 29], "max": [7, 21, 24, 25, 29], "calibr": [7, 10, 23, 25, 26, 28, 29], "techniqu": [7, 9, 13, 14, 16, 17, 19, 23, 25, 26, 28, 29, 30, 31, 34], "percentileencodinganalyz": 7, "num_bin": 7, "2048": 7, "percentil": 7, "100": 7, "set_percentil": 7, "clip": [7, 27, 29], "largest": 7, "smallest": 7, "valu": [7, 13, 18, 21, 23, 24, 25, 26, 29, 31, 33, 34], "from": [7, 10, 13, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 32, 35], "rang": [7, 13, 15, 18, 23, 24, 25, 26, 28, 29, 30, 33], "50": [7, 17], "indic": [7, 10, 17, 35], "sqnrencodinganalyz": 7, "asymmetric_delta_candid": 7, "17": 7, "symmetric_delta_candid": 7, "101": 7, "offset_candid": 7, "21": 7, "max_parallel": 7, "gamma": 7, "sqnr": [7, 29], "tupl": 7, "calcul": [7, 10, 18, 24, 25, 29], "int": 7, "per": [7, 10, 15, 23, 24, 25, 27, 28, 29, 30], "histogram": [7, 23, 25, 29, 30], "delta": [7, 29], "search": [7, 18, 26, 27], "over": [7, 10, 13, 18, 21, 33], "asymmetr": [7, 27, 29], "mode": [7, 22, 23, 27], "offset": [7, 11, 23, 25, 26, 29], "maximum": 7, "process": [7, 9, 14, 19, 21, 23, 24, 29], "paral": 7, "higher": [7, 15, 18, 26, 28], "memori": [7, 17, 21, 31, 34, 35], "usag": [7, 17, 21, 28], "faster": [7, 13, 19, 26], "weight": [7, 10, 13, 15, 17, 21, 23, 24, 25, 26, 27, 28, 29, 33], "factor": [7, 17, 21, 24], "nois": [7, 23, 24, 25, 26, 27], "less": [7, 16, 18], "compute_encodings_from_stat": 7, "stat": 7, "num_quant_bin": 7, "is_symmetr": [7, 27], "which": [7, 10, 13, 14, 15, 17, 18, 21, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34], "produc": [7, 18, 25, 32], "lowest": 7, "expect": [7, 21, 23, 25], "_histogram": 7, "A": [7, 10, 17, 23, 25, 26, 27, 28, 29], "length": 7, "split": 7, "bool": [7, 11], "els": [7, 24], "softwar": [9, 19, 21], "compress": [9, 16, 19, 30, 31, 33, 34, 35], "edg": [9, 19], "infer": [9, 15, 17, 19, 24, 26, 29, 30], "fix": [9, 19, 23, 28, 29, 30], "point": [9, 10, 19, 21, 23, 25, 28, 29, 33], "optim": [9, 13, 14, 19, 21, 23, 26, 29, 30, 32], "e": [9, 15, 17, 19, 26, 28, 35], "fp32": [9, 13, 19, 24, 25, 26, 28, 29], "post": [9, 13, 14, 19, 21, 26, 29, 30], "fine": [9, 17, 19, 23, 26, 29], "tune": [9, 17, 19, 23, 26, 29], "minim": [9, 19, 21, 23, 29], "accuraci": [9, 13, 14, 17, 18, 19, 21, 23, 24, 25, 26, 28, 29, 30, 33, 35], "loss": [9, 13, 19, 23, 25, 29], "incur": [9, 19, 25], "dure": [9, 10, 13, 19, 21, 23, 26, 27, 29, 32, 33], "design": [9, 24], "work": [9, 15, 21, 22, 24, 27], "see": [9, 16, 18, 19, 21, 23, 27, 28, 29, 31, 32, 33, 34], "tutori": 9, "view": [9, 19, 22, 32], "kera": [9, 15, 19, 23, 27, 29, 30], "document": [9, 17, 19, 30], "v1": 9, "pictur": [9, 16, 19], "show": [9, 19, 24, 28], "high": [9, 13, 15, 17, 18, 19, 24, 28, 30, 33], "level": [9, 15, 17, 18, 19, 23, 28, 32], "workflow": [9, 17, 19], "float": [9, 10, 23, 25, 28, 29, 33], "further": [9, 16, 19, 21, 23, 27], "small": [9, 15, 19, 23], "epoch": [9, 19, 21, 23, 26], "recov": [9, 19, 28, 29], "lost": [9, 19], "via": [9, 17, 19, 29], "torchscript": 9, "target": [9, 15, 17, 18, 19, 21, 23, 28, 29, 30], "runtim": [9, 17, 19, 21, 23, 25, 27, 29, 30], "like": [9, 19, 21, 23, 25, 26, 27, 32], "neural": [9, 14, 17, 19, 21, 23, 26, 28, 29, 34], "sdk": [9, 19], "instal": [9, 30], "quickstart": 9, "guid": [9, 17, 24, 28, 30], "adapt": [9, 13, 23, 25, 30], "round": [9, 13, 23, 25, 29], "adaround": [9, 14, 23, 28, 30], "analyz": [9, 10, 14, 16, 21, 22, 25, 29, 32, 33], "nn": [9, 10, 22, 30], "fakequantizationmixin": [9, 10], "quantizationmixin": [9, 10], "quantizedtensor": [9, 11], "product": [9, 19], "technologi": [9, 19], "its": [9, 10, 19, 23, 25, 29, 35], "subsidiari": [9, 19], "simul": [10, 19, 23, 26, 30], "effect": [10, 15, 23, 25, 27, 29], "reduc": [10, 16, 21, 24, 28, 30, 35], "integ": [10, 13, 23, 25], "bitwidth": [10, 11, 15, 23, 28, 29], "aimet": [10, 19, 22, 27], "standard": 10, "serv": [10, 32], "drop": [10, 14, 17, 21, 24, 25, 26, 28, 29], "counterpart": 10, "hold": [10, 27], "inherit": 10, "defin": [10, 22, 23, 25, 27, 29], "behavior": [10, 19], "determin": [10, 14, 17, 21, 23, 24, 25], "custom": [10, 28, 29], "state": [10, 21], "superset": 10, "mean": [10, 16, 27, 29], "intend": [10, 17], "matter": 10, "extens": 10, "coverag": 10, "limit": [10, 20], "basequantizationmixin": 10, "__quant_init__": 10, "initi": [10, 11, 13, 26, 28, 29], "invok": [10, 21, 23, 32, 33], "right": [10, 23, 35], "after": [10, 13, 14, 15, 17, 21, 23, 26, 28, 32, 33], "__init__": 10, "from_modul": 10, "creat": [10, 13, 15, 21, 22, 23, 26, 29], "same": [10, 11, 15, 24, 27, 29, 33], "attribut": [10, 25], "origin": [10, 16, 17, 21, 23, 24, 25, 26, 29, 32], "assign": 10, "linear": [10, 15, 16], "quantized_linear": 10, "param_quant": 10, "moduledict": 10, "bia": [10, 13, 16, 23, 24, 27, 28, 30], "get_original_modul": 10, "abstract": [10, 11], "quantized_forward": 10, "control": [10, 29], "within": [10, 17, 25, 29], "descript": [10, 22], "input_quant": 10, "modulelist": 10, "dict": [10, 11], "map": [10, 25, 27], "By": [10, 21, 27, 29], "structur": [10, 21], "appli": [10, 11, 13, 14, 15, 18, 21, 23, 24, 26, 27, 28, 29, 30, 32, 33], "index": [10, 17, 30], "respect": [10, 25], "channel": [10, 15, 17, 18, 20, 21, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35], "affin": [10, 11], "out_featur": 10, "in_featur": 10, "dimens": [10, 21, 28, 31, 34], "per_channel_quant": [10, 27], "quantizedequant": [10, 11], "elementwis": [10, 30], "multipli": [10, 17], "second": [10, 27], "qmul": 10, "quantizedmultipli": 10, "some": [10, 13, 17, 18, 21, 22, 23, 24, 26, 28, 29], "make": [10, 18, 21, 22, 23, 29], "sens": 10, "qadd": 10, "quantizedadd": 10, "befor": [10, 13, 14, 15, 21, 23, 26, 32, 33], "first": [10, 17, 21, 23, 26, 32], "disabl": [10, 18, 21, 25, 27, 29], "activ": [10, 23, 25, 26, 27, 28, 29], "them": [10, 13, 35], "exactli": [10, 29], "how": [10, 21, 24, 25, 28, 29], "sever": [10, 17], "sampl": [10, 16, 23, 24, 25, 26, 29], "calibration_data_load": 10, "get_encod": 11, "encodingbas": 11, "get_legacy_encod": 11, "register_quantization_paramet": 11, "param": [11, 27], "set_legacy_encod": 11, "scale": [11, 15, 23, 24, 25, 26, 29], "nearest": 13, "figur": [13, 18, 28, 35], "singl": [13, 24], "shown": [13, 21, 24, 25, 28], "illustr": [13, 18, 23, 31, 34], "smaller": [13, 19, 28, 31, 34], "subset": [13, 15, 25, 35], "unlabel": [13, 23, 25, 29], "far": 13, "decid": [13, 32], "whether": [13, 26], "specif": [13, 14, 15, 17, 19, 21, 22, 23, 24, 27, 30], "awai": 13, "abl": [13, 32, 33], "closer": 13, "low": [13, 15, 21, 23, 24, 28], "width": [13, 28, 29, 31, 34, 35], "quantizationsimmodel": [13, 15], "freez": 13, "refer": [13, 19, 23, 25, 26, 27, 29], "code": 13, "bc": 13, "bnf": 13, "batch": [13, 15, 23, 24, 25], "norm": [13, 15, 23, 24, 25], "fold": [13, 14, 15, 23, 24, 25, 30], "cle": [13, 23, 28, 30], "cross": [13, 14, 22, 23, 24, 25, 33], "hbf": 13, "qat": [13, 15, 19, 23, 28, 29, 30], "awar": [13, 15, 19, 23, 28, 29], "benefit": 13, "don": 13, "But": [13, 21], "benefici": [13, 25, 26], "consid": [13, 18, 23, 28], "better": [13, 14, 23, 24, 26], "help": [13, 18, 21, 23, 24, 25, 28, 32, 33], "Not": [13, 18], "hyper": [13, 26], "guidelin": [13, 17, 26], "coupl": 13, "requir": [13, 15, 17, 21, 23, 24, 27, 29], "expos": 13, "lead": [13, 15, 24, 28, 29], "stabl": 13, "mani": [13, 24, 29], "often": [13, 14, 21, 26], "approxim": [13, 17, 24, 25], "500": [13, 24, 25], "1000": [13, 24, 25], "size": [13, 21, 22, 31, 34], "loader": 13, "1024": [13, 22], "iter": [13, 24], "10000": 13, "moder": 13, "least": [13, 16], "beta": 13, "20": [13, 26], "warm": 13, "start": [13, 18, 21, 27, 29], "period": 13, "offer": 14, "suit": 14, "sequenc": [14, 15, 22, 27], "manual": [14, 21], "out": [14, 17, 21, 25], "variou": [14, 17, 21, 23, 28, 29, 30, 33], "combin": [14, 17, 21, 23, 24], "error": [14, 23, 26, 28, 29], "prone": 14, "consum": [14, 21], "addit": [14, 23, 26, 27, 30], "amount": [14, 27], "toler": [14, 17], "As": [14, 16, 17, 18, 21, 23, 24, 25, 29, 31, 34], "soon": 14, "threshold": 14, "reach": [14, 17], "stop": 14, "summari": 14, "save": [14, 29, 33], "autom": [14, 23], "prepar": [14, 23, 30], "check": [14, 23, 26, 28], "valid": [14, 23, 30], "convert": [14, 23, 33], "friendli": [14, 23, 24], "denot": 14, "select": [14, 17, 25, 29, 32, 35], "best": [14, 17, 21, 23, 29], "scheme": [14, 15, 18, 21, 25], "quantschem": 14, "preprat": 14, "mainli": 14, "consist": [14, 29, 35], "three": [14, 17, 33], "stage": 14, "batchnorm": [14, 24, 35], "effort": 14, "manner": 14, "until": 14, "meet": [14, 17, 18], "fail": [14, 22, 23], "satisfi": 14, "evalu": [14, 18, 21, 23, 25, 26, 29, 32], "goal": 14, "util": [15, 23], "individu": [15, 16, 17, 18, 21, 23, 25, 28], "normal": [15, 25], "adjust": [15, 16, 17, 23, 24, 28], "preceed": 15, "convolut": [15, 17, 21, 28], "learn": [15, 21, 23, 26, 29, 30], "pcq": [15, 25], "It": [15, 18, 23, 24, 27, 32, 33, 35], "veri": [15, 17, 21, 25, 33, 35], "NOT": [15, 35], "complet": [15, 28], "cover": [15, 27, 29], "scenario": [15, 21, 23, 35], "4": [15, 18, 23, 35], "decreas": 15, "where": [15, 18, 25, 26, 31, 34, 35], "main": [15, 27, 30, 33], "issu": [15, 19, 22, 28, 30, 32, 33], "depthwis": [15, 30], "separ": [15, 25, 28, 30], "sinc": [15, 17, 18, 29], "affect": [15, 27, 35], "oscil": 15, "quant": 15, "flow": [15, 23, 26, 28, 29], "diagram": [15, 18, 21, 29, 31, 34], "enumer": 15, "conv2d": [16, 21, 30, 35], "explain": [16, 21, 24, 29, 35], "differ": [16, 18, 21, 23, 24, 26, 27, 28, 29], "repeat": 16, "occurr": 16, "top": [16, 32], "detail": [16, 18, 19, 21, 23, 28, 29, 32, 33], "ratio": [16, 17, 32], "magnitud": 16, "choos": [16, 17, 21], "matrix": 16, "upstream": [16, 35], "could": [16, 35], "also": [16, 17, 18, 23, 25, 27, 28, 29, 30, 32, 33, 35], "gain": [16, 21], "presenc": 16, "connect": [16, 20, 34], "residu": 16, "sometim": [16, 21, 24, 25], "prevent": 16, "final": [16, 17, 18, 26, 28, 32], "wa": [16, 21, 27], "attempt": [16, 23, 24], "match": [16, 21, 25, 27, 28, 29, 35], "close": [16, 17, 29], "prior": [16, 23, 25], "collect": [16, 25], "random": [16, 25], "regress": 16, "typic": [17, 23, 25, 26, 27, 29, 32], "depth": [17, 28], "discuss": [17, 28, 29], "svd": [17, 18, 20, 21, 30], "spatial": [17, 18, 20, 21, 30], "ssvd": 17, "prune": [17, 18, 20, 21, 30, 35], "accumul": 17, "mac": [17, 21, 31, 34], "reduct": 17, "configur": [17, 20, 30], "uncompress": 17, "algorithm": [17, 18, 21, 28, 35], "overal": [17, 21, 28], "latenc": 17, "bandwidth": 17, "therefor": [17, 24], "improv": [17, 23, 26, 28, 33], "vari": [17, 18, 24, 33], "architectur": 17, "io": [17, 30], "At": [17, 21], "half": 17, "unknown": 17, "apriori": 17, "few": [17, 23, 28, 29], "cssvd": 17, "tri": [17, 23], "75": 17, "would": [17, 21, 27, 30, 32], "previou": [17, 18, 28], "here": [17, 26, 32], "pick": [17, 18, 21], "2b": 17, "rel": [17, 23, 28, 33], "ha": [17, 18, 21, 24, 26, 29, 32, 35], "avoid": 17, "2a": 17, "revisit": 17, "ccp": 17, "One": [17, 21, 31], "resnet": 17, "csvd": 17, "66": 17, "basi": [18, 21], "impact": [18, 28], "assess": 18, "sensit": [18, 23, 25, 28, 29, 30], "applic": [18, 22], "sure": [18, 22], "entir": [18, 21], "highest": 18, "remain": [18, 23, 24, 29], "execut": [18, 32], "eval": [18, 21, 32], "dictionari": [18, 21, 27], "column": 18, "tabl": [18, 22, 32], "captur": 18, "predefin": 18, "candid": [18, 21], "left": [18, 35], "unmodifi": 18, "score": [18, 21, 32], "last": [18, 20, 28], "baselin": [18, 26], "known": [18, 19], "monoton": 18, "fit": 18, "strict": [18, 27, 29], "increas": [18, 24, 27], "procedur": [18, 21], "curv": 18, "core": 18, "cost": [18, 21, 26], "constant": [18, 23], "everi": [18, 21, 26, 33], "interpol": 18, "total": [18, 29], "met": 18, "binari": 18, "solut": [18, 26, 28], "quickli": 18, "suggest": [18, 21, 24], "lower": [18, 23, 28], "lesser": [18, 21], "fall": [18, 27], "drstical": 18, "either": [19, 29], "framework": [19, 23, 27, 29], "meta": [19, 23], "h5": [19, 23], "hw": 19, "ptq": [19, 23, 25, 26], "take": [19, 21, 23, 24, 26, 27, 28, 35], "redund": 19, "fulli": 20, "conv": [20, 27, 30, 31, 34, 35], "dilat": 20, "than": [20, 26, 32], "modules_to_ignor": 20, "depthwiseconv2d": 20, "guidebook": [21, 23], "practic": 21, "advic": 21, "greedi": [21, 32], "phase": [21, 23], "choic": [21, 29], "nomin": 21, "And": 21, "tool": [21, 24, 33, 35], "ml": [21, 23, 24, 32, 33], "those": 21, "embed": [21, 28], "fc": 21, "certain": [21, 22, 23, 27], "decompos": [21, 31, 34], "term": [21, 31, 32, 33, 34], "present": [21, 24], "gener": [21, 23, 25, 26, 27, 29], "sharp": 21, "degrad": 21, "might": [21, 25], "respons": 21, "rate": [21, 26], "carefulli": 21, "decai": 21, "togeth": 21, "slow": 21, "someth": [21, 32], "speed": [21, 24, 30], "itself": [21, 29, 31, 34], "part": [21, 23, 24, 25], "experi": 21, "load": 21, "searcher": 21, "Or": 21, "granular": [21, 28, 29, 33], "strike": 21, "balanc": 21, "chosen": 21, "experiment": [21, 27], "major": 21, "sai": 21, "15": [21, 26], "end": 21, "xiangyu": 21, "zhang": 21, "jianhua": 21, "zou": 21, "kaim": 21, "he": 21, "jian": 21, "sun": 21, "deep": 21, "classif": 21, "detect": 21, "ieee": [21, 24], "transact": 21, "pattern": 21, "analysi": [21, 28], "intellig": 21, "vol": 21, "38": 21, "pp": 21, "1943": 21, "1955": 21, "oct": 21, "2016": 21, "yihui": 21, "intern": [21, 23, 24, 27], "confer": [21, 24], "vision": [21, 24], "iccv": [21, 24], "venic": 21, "2017": 21, "1398": 21, "1406": 21, "jaderberg": 21, "andrea": 21, "vedaldi": 21, "andrew": 21, "zisserman": 21, "expans": 21, "british": 21, "jan": 21, "2014": 21, "andrei": 21, "kuzmin": 21, "marku": [21, 24], "nagel": [21, 24], "saurabh": 21, "pitr": 21, "sandeep": 21, "pendyam": 21, "tijmen": [21, 24], "blankevoort": [21, 24], "taxonomi": 21, "cross_layer_equ": 22, "equalize_model": 22, "graph": [22, 23, 29, 32], "construct": 22, "restrict": 22, "successfulli": 22, "potenti": [22, 25, 32, 33], "workaround": 22, "primit": 22, "around": 22, "rewrit": 22, "slice": 22, "written": [22, 23], "caus": [22, 28, 29], "statement": 22, "bilinear": 22, "upsampl": 22, "129": 22, "align_corn": 22, "deconvolut": 22, "deeplabv3": 22, "avail": [22, 25, 27, 28], "address": [22, 28, 32], "subsequ": [22, 24, 26, 27], "howev": [23, 24, 26, 27, 29], "precis": 23, "introduc": [23, 27, 29], "due": [23, 24], "predict": 23, "estim": [23, 24], "re": 23, "oppos": [23, 27], "advantag": 23, "No": 23, "pipelin": [23, 26, 28, 29], "suffici": [23, 25, 26, 29], "dataset": [23, 24, 29], "even": 23, "fast": 23, "simpl": [23, 35], "easi": [23, 25], "still": [23, 28], "gap": 23, "insert": [23, 29], "robust": 23, "longer": [23, 26], "quantsim": [23, 26, 27, 30], "op": [23, 27, 30], "account": [23, 26, 28], "trainabl": 23, "bias": 23, "reflect": [23, 29], "autoqu": [23, 26, 30], "integr": 23, "describ": [23, 24, 28, 29], "standalon": 23, "consecut": [23, 24], "bn": [23, 30], "deprec": 23, "advis": [23, 27], "instead": [23, 24], "quantanalyz": [23, 30], "understand": [23, 27, 32, 33], "prep": 23, "been": [23, 26, 29, 35], "accord": [23, 26, 27, 29], "definit": 23, "align": 23, "retri": 23, "now": [23, 30, 35], "continu": [23, 24, 26, 28], "warn": 23, "hand": 23, "satisfactori": [23, 28], "bring": 23, "onto": 23, "thing": 23, "item": 23, "checkpoint": 23, "pb": 23, "involv": [23, 28], "trial": 23, "particular": [23, 27], "seem": 23, "off": [23, 24, 27], "bat": 23, "becom": 24, "paper": 24, "2019": 24, "arxiv": 24, "ab": 24, "1906": 24, "04721": 24, "surround": 24, "highlight": [24, 32, 33], "big": 24, "discrep": 24, "relu6": 24, "relu": [24, 27, 35], "accept": [24, 28], "wide": 24, "varianc": 24, "across": [24, 25], "seen": [24, 25], "significantli": 24, "similar": [24, 26, 29], "quantizaion": 24, "distribut": [24, 28, 29], "dynam": [24, 29, 30, 33], "did": 24, "shift": 24, "whose": [24, 27, 35], "empir": 24, "analyt": [24, 32, 33], "extract": 24, "bottleneck": [24, 28], "hybrid": 24, "approach": [24, 29], "mart": 24, "van": 24, "baalen": 24, "seoul": 24, "octob": 24, "hotspot": 25, "analys": 25, "callback": [25, 29], "dataload": 25, "mse": [25, 29], "plot": 25, "pretrain": [25, 26, 29], "dummi": 25, "label": [25, 26], "metric": [25, 29], "rune": 25, "relat": [25, 29], "doc": [25, 27, 32], "possibl": [25, 27, 28], "compar": [25, 26, 33], "situat": 25, "log": 25, "pinpoint": 25, "culprit": 25, "again": [25, 26, 32], "per_layer_quant_en": 25, "per_layer_quant_dis": 25, "axi": 25, "track": 25, "directli": [25, 29], "min_max_rang": 25, "folder": 25, "enhanc": [25, 29], "toss": 25, "outlier": [25, 29], "displai": [25, 32, 33], "activations_pdf": 25, "weights_pdf": 25, "monitor": 25, "contribut": [25, 28], "read": 25, "256": 25, "per_layer_mse_loss": 25, "mitig": [26, 29], "come": [26, 29], "usual": 26, "hyperparamet": 26, "sim": [26, 29], "node": [26, 29], "along": [26, 29], "accompani": 26, "found": [26, 29], "begin": [26, 27], "instanti": [26, 32], "throughout": [26, 27, 33], "themselv": 26, "aid": 26, "converg": 26, "int8": [26, 29, 33], "1e": 26, "6": 26, "schedul": 26, "divid": 26, "placement": 27, "rule": 27, "fuse": [27, 29], "most": 27, "six": 27, "overrul": 27, "turn": 27, "op_typ": 27, "purpos": 27, "empti": 27, "is_output_quant": 27, "is_quant": 27, "strict_symmetr": 27, "unsigned_symmetr": 27, "though": 27, "omit": 27, "altogeth": 27, "asid": 27, "govern": 27, "unsign": [27, 29], "back": 27, "gemm": 27, "is_input_quant": 27, "recogn": [27, 29], "keep": [27, 28], "convent": 27, "preced": 27, "supergroup": [27, 30], "made": 27, "op_list": 27, "member": 27, "adjac": 27, "sequenti": [27, 28], "branch": 27, "config": [27, 30], "entri": 27, "string": 27, "model_input": 27, "whatev": 27, "earlier": 27, "model_output": 27, "diagnost": 28, "strictli": 28, "debug": 28, "insight": [28, 32, 33], "why": 28, "underperform": 28, "tackl": 28, "chart": 28, "saniti": 28, "behav": 28, "similarli": 28, "ofth": 28, "independ": 28, "kept": 28, "convers": 28, "toward": 28, "signific": 28, "wise": 28, "uneven": 28, "vanilla": 28, "global": 28, "restor": 28, "rest": 28, "inner": 28, "loop": 28, "token": 28, "bert": 28, "reveal": 28, "problemat": [28, 33], "problem": 28, "resort": 28, "readi": 28, "revert": 28, "power": 28, "ultim": 29, "deploi": 29, "devic": 29, "copi": 29, "ingest": 29, "what": [29, 32], "feed": 29, "000": 29, "yield": 29, "dequantiz": 29, "hook": 29, "intercept": 29, "four": 29, "q": 29, "clamp": 29, "zero": [29, 30], "vice": 29, "versa": 29, "equat": 29, "textrm": 29, "dfrac": 29, "quad": 29, "whole": 29, "strong": 29, "excess": 29, "signal": 29, "squar": 29, "qmin": 29, "qmax": 29, "satur": 29, "erro": 29, "static": 29, "alongsid": 29, "wherea": 29, "ones": 29, "just": [29, 32, 35], "sign": 29, "non": 29, "intermedi": 29, "matmul": 30, "slim": 30, "backslash": 30, "cl": 30, "user_guid": 30, "api_doc": 30, "quantizablemultiheadattent": 30, "transform": 30, "kyuykim": 30, "multi": 30, "mangal": 30, "logic": 30, "geunle": 30, "bug": 30, "correctli": 30, "leaf": 30, "klhsieh": 30, "n": 30, "akhobar": 30, "resid": 30, "info": 30, "multiheadattent": 30, "ashvkuma": 30, "mha": 30, "pdf": 30, "fp16": 30, "conv1d": 30, "convtranspose1d": 30, "concat": 30, "minor": 30, "stand": [30, 31, 34], "adaptiveround": 30, "recurr": 30, "rnn": 30, "lstm": 30, "gru": 30, "packag": 30, "decomposit": [31, 34], "singular": [31, 34], "\ud835\udc5a": [31, 34], "\ud835\udc5b": [31, 34], "\u210e": [31, 34], "\ud835\udc64": [31, 34], "give": [31, 34], "height": [31, 34, 35], "\ud835\udc58": [31, 34], "k": 31, "rank": [31, 34], "larger": [31, 34], "degre": [31, 34], "assist": [32, 33], "progress": [32, 33], "computation": [32, 33], "task": [32, 33], "websocket": 32, "tell": 32, "listen": 32, "rather": 32, "5006": 32, "compress_model": 32, "necessari": 32, "look": 32, "visualizecompress": 32, "display_eval_scor": 32, "display_comp_ratio_plot": 32, "directori": 33, "lot": 33, "anoth": [34, 35], "lose": 35, "much": 35, "explicitli": 35, "unnecessari": 35, "pictori": 35, "volum": 35, "hxwx8": 35, "hxwx5": 35, "simpli": 35, "propag": 35, "That": 35, "teh": 35, "green": 35, "color": 35, "side": 35, "action": 35, "taken": 35, "pink": 35, "orang": 35}, "objects": {"aimet_torch.v2.nn": [[4, 0, 1, "", "FakeQuantizationMixin"], [5, 0, 1, "", "QuantizationMixin"]], "aimet_torch.v2.nn.FakeQuantizationMixin": [[4, 1, 1, "", "compute_encodings"], [4, 1, 1, "", "implements"], [4, 1, 1, "", "wrap"]], "aimet_torch.v2.nn.QuantizationMixin": [[5, 1, 1, "", "compute_encodings"], [5, 1, 1, "", "get_default_kernel"], [5, 1, 1, "", "get_kernel"], [5, 1, 1, "", "implements"], [5, 1, 1, "", "set_default_kernel"], [5, 1, 1, "", "set_kernel"], [5, 1, 1, "", "wrap"]], "aimet_torch.v2.nn.base": [[10, 0, 1, "", "BaseQuantizationMixin"]], "aimet_torch.v2.nn.base.BaseQuantizationMixin": [[10, 1, 1, "", "__quant_init__"], [10, 1, 1, "", "compute_encodings"], [10, 1, 1, "", "from_module"], [10, 1, 1, "", "get_original_module"], [10, 1, 1, "", "quantized_forward"]], "aimet_torch.v2.quantization.affine.quantizer": [[11, 0, 1, "", "Quantize"], [11, 0, 1, "", "QuantizeDequantize"], [11, 0, 1, "", "QuantizerBase"]], "aimet_torch.v2.quantization.affine.quantizer.Quantize": [[11, 1, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize": [[11, 1, 1, "", "forward"]], "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase": [[11, 1, 1, "", "compute_encodings"], [11, 1, 1, "", "get_encoding"], [11, 1, 1, "", "get_legacy_encodings"], [11, 1, 1, "", "is_initialized"], [11, 1, 1, "", "register_quantization_parameter"], [11, 1, 1, "", "set_legacy_encodings"]], "aimet_torch.v2.quantization": [[7, 2, 0, "-", "encoding_analyzer"]], "aimet_torch.v2.quantization.encoding_analyzer": [[7, 0, 1, "", "EncodingAnalyzer"], [7, 0, 1, "", "MinMaxEncodingAnalyzer"], [7, 0, 1, "", "PercentileEncodingAnalyzer"], [7, 0, 1, "", "SqnrEncodingAnalyzer"]], "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer": [[7, 1, 1, "", "set_percentile"]], "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer": [[7, 1, 1, "", "compute_encodings_from_stats"]], "aimet_torch.v2.quantization.tensor": [[6, 0, 1, "", "DequantizedTensor"], [6, 0, 1, "", "QuantizedTensor"]], "aimet_torch.v2.quantization.tensor.DequantizedTensor": [[6, 1, 1, "", "dequantize"], [6, 1, 1, "", "quantize"], [6, 1, 1, "", "quantized_repr"]], "aimet_torch.v2.quantization.tensor.QuantizedTensor": [[6, 1, 1, "", "dequantize"], [6, 1, 1, "", "quantize"], [6, 1, 1, "", "quantized_repr"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:module"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "module", "Python module"]}, "titleterms": {"aimet": [0, 1, 2, 9, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35], "instal": [0, 1, 2, 19], "releas": [0, 1, 19, 30], "packag": [0, 1, 2], "system": 0, "requir": [0, 25], "instruct": 0, "docker": 1, "set": 1, "variant": 1, "us": [1, 13, 21, 23, 32], "prebuilt": 1, "imag": 1, "build": 1, "local": 1, "start": [1, 9, 19, 32], "contain": 1, "from": 1, "pypi": 1, "environ": [1, 2], "setup": [1, 2], "prerequisit": 2, "gpu": 2, "pytorch": [2, 9, 22, 23, 33], "1": [2, 30], "13": [2, 30], "onnx": 2, "2": [2, 30], "tensorflow": [2, 23, 33], "common": [2, 13], "debian": 2, "torch": 2, "replac": 2, "pillow": 2, "simd": 2, "onnxruntim": 2, "post": [2, 8, 23, 24], "step": 2, "nn": [4, 5], "fakequantizationmixin": 4, "top": [4, 5, 6, 7, 10, 11], "level": [4, 5, 6, 7, 10, 11], "api": [4, 5, 6, 7, 9, 10, 11], "quantizationmixin": 5, "quantiz": [6, 8, 10, 11, 23, 24, 26, 27, 28, 29, 33], "quantizedtensor": 6, "encod": [7, 10, 29], "analyz": 7, "train": [8, 23, 24, 26], "welcom": 9, "ai": [9, 19], "model": [9, 19, 21, 22, 23], "effici": [9, 19], "toolkit": [9, 19], "doc": 9, "get": [9, 19, 21], "exampl": 9, "featur": [9, 17, 19, 23, 28], "descript": [9, 25], "modul": 10, "configur": [10, 27, 29], "comput": 10, "quickstart": 12, "guid": [12, 19], "adaround": 13, "case": [13, 21, 23], "terminologi": 13, "autoqu": 14, "overview": [14, 15, 18, 19, 21, 24, 25, 26, 27, 29, 32, 33, 35], "workflow": [14, 15, 23, 26, 29], "bn": 15, "re": 15, "estim": 15, "channel": 16, "prune": 16, "overal": 16, "procedur": 16, "select": [16, 18, 21], "winnow": [16, 35], "weight": [16, 34], "reconstruct": 16, "compress": [17, 18, 21, 32], "guidebook": [17, 28], "greedi": 18, "ratio": [18, 21], "how": [18, 27, 32, 35], "work": [18, 35], "per": [18, 21], "layer": [18, 21], "explor": 18, "user": [19, 24], "inform": 19, "toc": 19, "tree": 19, "known": 20, "issu": 20, "option": 21, "techniqu": [21, 24], "better": 21, "result": 21, "rank": 21, "round": 21, "fine": 21, "tune": 21, "faq": [21, 24], "refer": [21, 24], "guidelin": [22, 23], "debug": 23, "analysi": [23, 25], "tool": [23, 32], "flow": 24, "quantanalyz": 25, "detail": 25, "awar": 26, "qat": 26, "mode": 26, "recommend": 26, "simul": [27, 29], "file": 27, "structur": 27, "individu": 27, "section": 27, "quantsim": 29, "nois": 29, "determin": 29, "paramet": 29, "scheme": 29, "op": 29, "frequent": 29, "ask": 29, "question": 29, "note": 30, "22": 30, "0": 30, "21": 30, "20": 30, "19": 30, "py37": 30, "18": 30, "17": 30, "16": 30, "14": 30, "spatial": 31, "svd": [31, 34], "visual": [32, 33], "design": 32, "bokeh": 32, "server": 32, "session": 32}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"AIMET Installation": [[0, "aimet-installation"]], "Release packages": [[0, "release-packages"]], "System Requirements": [[0, "system-requirements"]], "Installation Instructions": [[0, "installation-instructions"]], "AIMET Installation in Docker": [[1, "aimet-installation-in-docker"]], "Set variant": [[1, "set-variant"]], "Use prebuilt docker image": [[1, "use-prebuilt-docker-image"]], "Build docker image locally": [[1, "build-docker-image-locally"]], "Start docker container": [[1, "start-docker-container"]], "Install AIMET packages": [[1, "install-aimet-packages"], [2, "install-aimet-packages"]], "From PyPI": [[1, "from-pypi"]], "From Release Package": [[1, "from-release-package"]], "Environment setup": [[1, "environment-setup"], [2, "environment-setup"]], "AIMET Installation and Setup": [[2, "aimet-installation-and-setup"]], "Install prerequisite packages": [[2, "install-prerequisite-packages"]], "Install GPU packages": [[2, "install-gpu-packages"]], "Install GPU packages for PyTorch 1.13 or ONNX": [[2, "install-gpu-packages-for-pytorch-1-13-or-onnx"]], "Install GPU packages for PyTorch 2.1 or TensorFlow": [[2, "install-gpu-packages-for-pytorch-2-1-or-tensorflow"]], "Install common debian packages": [[2, "install-common-debian-packages"]], "Install tensorflow GPU debian packages": [[2, "install-tensorflow-gpu-debian-packages"]], "Install torch GPU debian packages": [[2, "install-torch-gpu-debian-packages"]], "Install ONNX GPU debian packages": [[2, "install-onnx-gpu-debian-packages"]], "Replace Pillow with Pillow-SIMD": [[2, "replace-pillow-with-pillow-simd"]], "Replace onnxruntime with onnxruntime-gpu": [[2, "replace-onnxruntime-with-onnxruntime-gpu"]], "Post installation steps": [[2, "post-installation-steps"]], "nn.FakeQuantizationMixin": [[4, "nn-fakequantizationmixin"]], "Top-level API": [[4, "top-level-api"], [5, "top-level-api"], [6, "top-level-api"], [7, "module-aimet_torch.v2.quantization.encoding_analyzer"], [10, "top-level-api"], [11, "top-level-api"]], "nn.QuantizationMixin": [[5, "nn-quantizationmixin"]], "quantization.QuantizedTensor": [[6, "quantization-quantizedtensor"]], "Encoding Analyzers": [[7, "encoding-analyzers"]], "Post-Training Quantization": [[8, "post-training-quantization"], [23, "post-training-quantization"]], "Welcome to AI Model Efficiency Toolkit PyTorch API Docs!": [[9, "welcome-to-ai-model-efficiency-toolkit-pytorch-api-docs"]], "Getting Started": [[9, null], [19, "getting-started"]], "Examples": [[9, null]], "Feature Descriptions": [[9, null]], "AIMET PyTorch API": [[9, null]], "Quantized Modules": [[10, "quantized-modules"]], "Configuration": [[10, "configuration"]], "Computing Encodings": [[10, "computing-encodings"]], "Quantizers": [[11, "quantizers"]], "Quickstart Guide": [[12, "quickstart-guide"]], "AIMET AdaRound": [[13, "aimet-adaround"]], "AdaRound Use Cases": [[13, "adaround-use-cases"]], "Common terminology": [[13, "common-terminology"]], "Use Cases": [[13, "use-cases"], [23, "use-cases"]], "AIMET AutoQuant": [[14, "aimet-autoquant"]], "Overview": [[14, "overview"], [15, "overview"], [18, "overview"], [19, "overview"], [21, "overview"], [24, "overview"], [25, "overview"], [26, "overview"], [27, "overview"], [29, "overview"], [32, "overview"], [33, "overview"], [35, "overview"]], "Workflow": [[14, "workflow"], [15, "workflow"]], "AIMET BN Re-estimation": [[15, "aimet-bn-re-estimation"]], "AIMET Channel Pruning": [[16, "aimet-channel-pruning"]], "Overall Procedure": [[16, "overall-procedure"]], "Channel Selection": [[16, "channel-selection"]], "Winnowing": [[16, "winnowing"]], "Weight Reconstruction": [[16, "weight-reconstruction"]], "AIMET Compression Features Guidebook": [[17, "aimet-compression-features-guidebook"]], "AIMET Greedy Compression Ratio Selection": [[18, "aimet-greedy-compression-ratio-selection"]], "How it works": [[18, "how-it-works"]], "Per-layer Exploration": [[18, "per-layer-exploration"]], "Compression Ratio Selection": [[18, "compression-ratio-selection"]], "AI Model Efficiency Toolkit User Guide": [[19, "ai-model-efficiency-toolkit-user-guide"]], "Features": [[19, "features"]], "Release Information": [[19, "release-information"]], "Installation Guide": [[19, "installation-guide"]], "toc tree": [[19, "toc-tree"]], "AIMET Known Issues": [[20, "aimet-known-issues"]], "AIMET Model Compression": [[21, "aimet-model-compression"]], "Use Case": [[21, "use-case"]], "Compression ratio selection": [[21, "compression-ratio-selection"]], "Model Compression": [[21, "model-compression"]], "Optional techniques to get better compression results": [[21, "optional-techniques-to-get-better-compression-results"]], "Rank Rounding": [[21, "rank-rounding"]], "Per-layer Fine-tuning": [[21, "per-layer-fine-tuning"]], "FAQs": [[21, "faqs"], [24, "faqs"]], "References": [[21, "references"], [24, "references"]], "Model Guidelines for PyTorch": [[22, "model-guidelines-for-pytorch"]], "AIMET Model Quantization": [[23, "aimet-model-quantization"]], "AIMET Quantization Features": [[23, "aimet-quantization-features"]], "Debugging/Analysis Tools": [[23, "debugging-analysis-tools"]], "AIMET Quantization Workflow": [[23, "aimet-quantization-workflow"]], "PyTorch": [[23, "pytorch"], [33, "pytorch"]], "Tensorflow": [[23, "tensorflow"]], "Debugging Guidelines": [[23, "debugging-guidelines"]], "AIMET Post-Training Quantization Techniques": [[24, "aimet-post-training-quantization-techniques"]], "User Flow": [[24, "user-flow"]], "AIMET QuantAnalyzer": [[25, "aimet-quantanalyzer"]], "Requirements": [[25, "requirements"]], "Detailed Analysis Descriptions": [[25, "detailed-analysis-descriptions"]], "AIMET Quantization Aware Training": [[26, "aimet-quantization-aware-training"]], "QAT workflow": [[26, "qat-workflow"]], "QAT modes": [[26, "qat-modes"]], "Recommendations for Quantization-Aware Training": [[26, "recommendations-for-quantization-aware-training"]], "Quantization Simulation Configuration": [[27, "quantization-simulation-configuration"]], "Configuration File Structure": [[27, "configuration-file-structure"]], "How to configure individual Configuration File Sections": [[27, "how-to-configure-individual-configuration-file-sections"]], "AIMET Quantization Features Guidebook": [[28, "aimet-quantization-features-guidebook"]], "AIMET Quantization Simulation": [[29, "aimet-quantization-simulation"]], "QuantSim Workflow": [[29, "quantsim-workflow"]], "Simulating Quantization Noise": [[29, "simulating-quantization-noise"]], "Determining Quantization Parameters (Encodings)": [[29, "determining-quantization-parameters-encodings"]], "Quantization Schemes": [[29, "quantization-schemes"]], "Configuring Quantization Simulation Ops": [[29, "configuring-quantization-simulation-ops"]], "Frequently Asked Questions": [[29, "frequently-asked-questions"]], "AIMET Release Notes": [[30, "aimet-release-notes"]], "1.22.2": [[30, "id1"]], "1.22.1": [[30, "id2"]], "1.22.0": [[30, "id3"]], "1.21.0": [[30, "id4"]], "1.20.0": [[30, "id5"]], "1.19.1.py37": [[30, "py37"]], "1.19.1": [[30, "id6"]], "1.18.0.py37": [[30, "id7"]], "1.18.0": [[30, "id8"]], "1.17.0.py37": [[30, "id9"]], "1.17.0": [[30, "id10"]], "1.16.2.py37": [[30, "id11"]], "1.16.2": [[30, "id12"]], "1.16.1.py37": [[30, "id13"]], "1.16.1": [[30, "id14"]], "1.16.0": [[30, "id15"]], "1.14.0": [[30, "id16"]], "1.13.0": [[30, "id17"]], "AIMET Spatial SVD": [[31, "aimet-spatial-svd"]], "AIMET Visualization": [[32, "aimet-visualization"]], "Design": [[32, "design"]], "Compression": [[32, "compression"]], "Starting a Bokeh Server Session:": [[32, "starting-a-bokeh-server-session"]], "How to use the tool": [[32, "how-to-use-the-tool"]], "AIMET Visualization for Quantization": [[33, "aimet-visualization-for-quantization"]], "Quantization": [[33, "quantization"]], "TensorFlow": [[33, "tensorflow"]], "AIMET Weight SVD": [[34, "aimet-weight-svd"]], "AIMET Winnowing": [[35, "aimet-winnowing"]], "Winnowing Overview": [[35, "winnowing-overview"]], "How Winnowing Works": [[35, "how-winnowing-works"]]}, "indexentries": {"fakequantizationmixin (class in aimet_torch.v2.nn)": [[4, "aimet_torch.v2.nn.FakeQuantizationMixin"]], "compute_encodings() (aimet_torch.v2.nn.fakequantizationmixin method)": [[4, "aimet_torch.v2.nn.FakeQuantizationMixin.compute_encodings"]], "implements() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[4, "aimet_torch.v2.nn.FakeQuantizationMixin.implements"]], "wrap() (aimet_torch.v2.nn.fakequantizationmixin class method)": [[4, "aimet_torch.v2.nn.FakeQuantizationMixin.wrap"]], "quantizationmixin (class in aimet_torch.v2.nn)": [[5, "aimet_torch.v2.nn.QuantizationMixin"]], "compute_encodings() (aimet_torch.v2.nn.quantizationmixin method)": [[5, "aimet_torch.v2.nn.QuantizationMixin.compute_encodings"]], "get_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[5, "aimet_torch.v2.nn.QuantizationMixin.get_default_kernel"]], "get_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[5, "aimet_torch.v2.nn.QuantizationMixin.get_kernel"]], "implements() (aimet_torch.v2.nn.quantizationmixin class method)": [[5, "aimet_torch.v2.nn.QuantizationMixin.implements"]], "set_default_kernel() (aimet_torch.v2.nn.quantizationmixin class method)": [[5, "aimet_torch.v2.nn.QuantizationMixin.set_default_kernel"]], "set_kernel() (aimet_torch.v2.nn.quantizationmixin method)": [[5, "aimet_torch.v2.nn.QuantizationMixin.set_kernel"]], "wrap() (aimet_torch.v2.nn.quantizationmixin class method)": [[5, "aimet_torch.v2.nn.QuantizationMixin.wrap"]], "dequantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[6, "aimet_torch.v2.quantization.tensor.DequantizedTensor"]], "quantizedtensor (class in aimet_torch.v2.quantization.tensor)": [[6, "aimet_torch.v2.quantization.tensor.QuantizedTensor"]], "dequantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[6, "aimet_torch.v2.quantization.tensor.DequantizedTensor.dequantize"]], "dequantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[6, "aimet_torch.v2.quantization.tensor.QuantizedTensor.dequantize"]], "quantize() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[6, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantize"]], "quantize() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[6, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantize"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.dequantizedtensor method)": [[6, "aimet_torch.v2.quantization.tensor.DequantizedTensor.quantized_repr"]], "quantized_repr() (aimet_torch.v2.quantization.tensor.quantizedtensor method)": [[6, "aimet_torch.v2.quantization.tensor.QuantizedTensor.quantized_repr"]], "encodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[7, "aimet_torch.v2.quantization.encoding_analyzer.EncodingAnalyzer"]], "minmaxencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[7, "aimet_torch.v2.quantization.encoding_analyzer.MinMaxEncodingAnalyzer"]], "percentileencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[7, "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer"]], "sqnrencodinganalyzer (class in aimet_torch.v2.quantization.encoding_analyzer)": [[7, "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer"]], "aimet_torch.v2.quantization.encoding_analyzer": [[7, "module-aimet_torch.v2.quantization.encoding_analyzer"]], "compute_encodings_from_stats() (aimet_torch.v2.quantization.encoding_analyzer.sqnrencodinganalyzer method)": [[7, "aimet_torch.v2.quantization.encoding_analyzer.SqnrEncodingAnalyzer.compute_encodings_from_stats"]], "module": [[7, "module-aimet_torch.v2.quantization.encoding_analyzer"]], "set_percentile() (aimet_torch.v2.quantization.encoding_analyzer.percentileencodinganalyzer method)": [[7, "aimet_torch.v2.quantization.encoding_analyzer.PercentileEncodingAnalyzer.set_percentile"]], "basequantizationmixin (class in aimet_torch.v2.nn.base)": [[10, "aimet_torch.v2.nn.base.BaseQuantizationMixin"]], "__quant_init__() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[10, "aimet_torch.v2.nn.base.BaseQuantizationMixin.__quant_init__"]], "compute_encodings() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[10, "aimet_torch.v2.nn.base.BaseQuantizationMixin.compute_encodings"]], "from_module() (aimet_torch.v2.nn.base.basequantizationmixin class method)": [[10, "aimet_torch.v2.nn.base.BaseQuantizationMixin.from_module"]], "get_original_module() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[10, "aimet_torch.v2.nn.base.BaseQuantizationMixin.get_original_module"]], "quantized_forward() (aimet_torch.v2.nn.base.basequantizationmixin method)": [[10, "aimet_torch.v2.nn.base.BaseQuantizationMixin.quantized_forward"]], "quantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[11, "aimet_torch.v2.quantization.affine.quantizer.Quantize"]], "quantizedequantize (class in aimet_torch.v2.quantization.affine.quantizer)": [[11, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize"]], "quantizerbase (class in aimet_torch.v2.quantization.affine.quantizer)": [[11, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase"]], "compute_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[11, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.compute_encodings"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantize method)": [[11, "aimet_torch.v2.quantization.affine.quantizer.Quantize.forward"]], "forward() (aimet_torch.v2.quantization.affine.quantizer.quantizedequantize method)": [[11, "aimet_torch.v2.quantization.affine.quantizer.QuantizeDequantize.forward"]], "get_encoding() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[11, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_encoding"]], "get_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[11, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.get_legacy_encodings"]], "is_initialized() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[11, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.is_initialized"]], "register_quantization_parameter() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[11, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.register_quantization_parameter"]], "set_legacy_encodings() (aimet_torch.v2.quantization.affine.quantizer.quantizerbase method)": [[11, "aimet_torch.v2.quantization.affine.quantizer.QuantizerBase.set_legacy_encodings"]]}})